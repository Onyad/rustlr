//Parser generated by rustlr for grammar preprocessor
    
#![allow(unused_variables)]
#![allow(non_snake_case)]
#![allow(non_camel_case_types)]
#![allow(unused_parens)]
#![allow(unused_mut)]
#![allow(unused_imports)]
#![allow(unused_assignments)]
#![allow(dead_code)]
#![allow(unreachable_patterns)]
#![allow(irrefutable_let_patterns)]
use std::rc::Rc;
use std::cell::RefCell;
extern crate rustlr;
use rustlr::{Tokenizer,TerminalToken,ZCParser,ZCRProduction,Stateaction,decode_action};
use rustlr::{StrTokenizer,RawToken,LexSource};
use std::collections::{HashMap,HashSet};
use rustlr::LBox;
use crate::preprocessor_ast;
use crate::preprocessor_ast::*;

static SYMBOLS:[&'static str;8] = ["_WILDCARD_TOKEN_","directive","junk","S","Stuff","NEWRENT_0_0","START","EOF"];

static TABLE:[u64;19] = [4294967298,21474902017,8589934594,12885032961,30064771074,281505041612802,281492156841985,281483566841856,281479272005632,562980018192387,844429225361410,844433520328706,844454995165186,1125904201875458,1125908496842754,1125929971679234,1407404948520962,1407383473684482,1407379178717186,];


fn _semaction_rule_0_<'lt>(parser:&mut ZCParser<RetTypeEnum<'lt>,()>) -> Vec<LBox<Stuff<'lt>>> {
 Vec::new() }

fn _semaction_rule_1_<'lt>(parser:&mut ZCParser<RetTypeEnum<'lt>,()>) -> Vec<LBox<Stuff<'lt>>> {
let mut _item1_ = if let RetTypeEnum::Enumvariant_12(_x_12)=parser.popstack().value { _x_12 } else {<Stuff<'lt>>::default()}; let mut _item0_ = if let RetTypeEnum::Enumvariant_11(_x_11)=parser.popstack().value { _x_11 } else {<Vec<LBox<Stuff<'lt>>>>::default()};  _item0_.push(parser.lbx(1,_item1_)); _item0_ }

fn _semaction_rule_2_<'lt>(parser:&mut ZCParser<RetTypeEnum<'lt>,()>) -> S<'lt> {
let mut _item0_ = if let RetTypeEnum::Enumvariant_11(_x_11)=parser.popstack().value { _x_11 } else {<Vec<LBox<Stuff<'lt>>>>::default()};  S(_item0_,) }

fn _semaction_rule_3_<'lt>(parser:&mut ZCParser<RetTypeEnum<'lt>,()>) -> Stuff<'lt> {
let mut d = if let RetTypeEnum::Enumvariant_3(_x_3)=parser.popstack().value { _x_3 } else {<&'lt str>::default()}; println!("See directive: {}",d);   Stuff::directive(d) }

fn _semaction_rule_4_<'lt>(parser:&mut ZCParser<RetTypeEnum<'lt>,()>) -> Stuff<'lt> {
let mut _item0_ = if let RetTypeEnum::Enumvariant_10(_x_10)=parser.popstack().value { _x_10 } else {<()>::default()};  Stuff::junk }

fn _semaction_rule_5_<'lt>(parser:&mut ZCParser<RetTypeEnum<'lt>,()>) -> () {
let mut _item0_ = if let RetTypeEnum::Enumvariant_0(_x_0)=parser.popstack().value { _x_0 } else {<S<'lt>>::default()}; <()>::default()}

pub fn make_parser<'lt>() -> ZCParser<RetTypeEnum<'lt>,()>
{
 let mut parser1:ZCParser<RetTypeEnum<'lt>,()> = ZCParser::new(6,6);
 let mut rule = ZCRProduction::<RetTypeEnum<'lt>,()>::new_skeleton("start");
 rule = ZCRProduction::<RetTypeEnum<'lt>,()>::new_skeleton("NEWRENT_0_0");
 rule.Ruleaction = |parser|{  RetTypeEnum::Enumvariant_11(_semaction_rule_0_(parser)) };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<RetTypeEnum<'lt>,()>::new_skeleton("NEWRENT_0_0");
 rule.Ruleaction = |parser|{  RetTypeEnum::Enumvariant_11(_semaction_rule_1_(parser)) };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<RetTypeEnum<'lt>,()>::new_skeleton("S");
 rule.Ruleaction = |parser|{  RetTypeEnum::Enumvariant_0(_semaction_rule_2_(parser)) };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<RetTypeEnum<'lt>,()>::new_skeleton("Stuff");
 rule.Ruleaction = |parser|{  RetTypeEnum::Enumvariant_12(_semaction_rule_3_(parser)) };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<RetTypeEnum<'lt>,()>::new_skeleton("Stuff");
 rule.Ruleaction = |parser|{  RetTypeEnum::Enumvariant_12(_semaction_rule_4_(parser)) };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<RetTypeEnum<'lt>,()>::new_skeleton("START");
 rule.Ruleaction = |parser|{  RetTypeEnum::Enumvariant_10(_semaction_rule_5_(parser)) };
 parser1.Rules.push(rule);
 parser1.Errsym = "";

 for i in 0..19 {
   let symi = ((TABLE[i] & 0x0000ffff00000000) >> 32) as usize;
   let sti = ((TABLE[i] & 0xffff000000000000) >> 48) as usize;
   parser1.RSM[sti].insert(SYMBOLS[symi],decode_action(TABLE[i]));
 }

 for s in SYMBOLS { parser1.Symset.insert(s); }

 load_extras(&mut parser1);
 return parser1;
} //make_parser

pub fn parse_with<'lt>(parser:&mut ZCParser<RetTypeEnum<'lt>,()>, lexer:&mut preprocessorlexer<'lt>) -> Result<S<'lt>,S<'lt>>
{
  lexer.shared_state = Rc::clone(&parser.shared_state);
  if let RetTypeEnum::Enumvariant_0(_xres_) = parser.parse(lexer) {
     if !parser.error_occurred() {Ok(_xres_)} else {Err(_xres_)}
  } else { Err(<S<'lt>>::default())}
}//parse_with public function

pub fn parse_train_with<'lt>(parser:&mut ZCParser<RetTypeEnum<'lt>,()>, lexer:&mut preprocessorlexer<'lt>, parserpath:&str) -> Result<S<'lt>,S<'lt>>
{
  lexer.shared_state = Rc::clone(&parser.shared_state);
  if let RetTypeEnum::Enumvariant_0(_xres_) = parser.parse_train(lexer,parserpath) {
     if !parser.error_occurred() {Ok(_xres_)} else {Err(_xres_)}
  } else { Err(<S<'lt>>::default())}
}//parse_train_with public function

//Enum for return values 
pub enum RetTypeEnum<'lt> {
  Enumvariant_11(Vec<LBox<Stuff<'lt>>>),
  Enumvariant_3(&'lt str),
  Enumvariant_0(S<'lt>),
  Enumvariant_10(()),
  Enumvariant_2((usize,usize)),
  Enumvariant_12(Stuff<'lt>),
}
impl<'lt> Default for RetTypeEnum<'lt> { fn default()->Self {RetTypeEnum::Enumvariant_0(<S<'lt>>::default())} }


// Lexical Scanner using RawToken and StrTokenizer
pub struct preprocessorlexer<'lt> {
   stk: StrTokenizer<'lt>,
   keywords: HashSet<&'static str>,
   lexnames: HashMap<&'static str,&'static str>,
   shared_state: Rc<RefCell<()>>,
}
impl<'lt> preprocessorlexer<'lt> 
{
  pub fn from_str(s:&'lt str) -> preprocessorlexer<'lt>  {
    Self::new(StrTokenizer::from_str(s))
  }
  pub fn from_source(s:&'lt LexSource<'lt>) -> preprocessorlexer<'lt>  {
    Self::new(StrTokenizer::from_source(s))
  }
  pub fn new(mut stk:StrTokenizer<'lt>) -> preprocessorlexer<'lt> {
    let mut lexnames = HashMap::with_capacity(64);
    let mut keywords = HashSet::with_capacity(64);
    let shared_state = Rc::new(RefCell::new(<()>::default()));
    for kw in ["junk","_WILDCARD_TOKEN_","directive",] {keywords.insert(kw);}
    for c in [] {stk.add_single(c);}
    for d in [] {stk.add_double(d);}
    for d in [] {stk.add_triple(d);}
    for (k,v) in [] {lexnames.insert(k,v);}
    stk.add_custom("directive",r"^(?m)^#(.|(\\\n|\\\r))*$");
    stk.add_custom("junk",r"^(?m)^.*$");
    preprocessorlexer {stk,keywords,lexnames,shared_state}
  }
}
impl<'lt> Tokenizer<'lt,RetTypeEnum<'lt>> for preprocessorlexer<'lt>
{
   fn nextsym(&mut self) -> Option<TerminalToken<'lt,RetTypeEnum<'lt>>> {
    let tokopt = self.stk.next_token();
    if let None = tokopt {return None;}
    let token = tokopt.unwrap();
    match token.0 {
      RawToken::Alphanum(sym) if self.keywords.contains(sym) => {
        let truesym = self.lexnames.get(sym).unwrap_or(&sym);
        Some(TerminalToken::from_raw(token,truesym,<RetTypeEnum<'lt>>::default()))
      },
      RawToken:: Custom("directive",d)  => Some(TerminalToken::from_raw(token,"directive",RetTypeEnum::Enumvariant_3( d
))),
      RawToken:: Custom("junk",_)  => Some(TerminalToken::from_raw(token,"junk",RetTypeEnum::Enumvariant_10( ()
))),
      RawToken::Symbol(s) if self.lexnames.contains_key(s) => {
        let tname = self.lexnames.get(s).unwrap();
        Some(TerminalToken::from_raw(token,tname,<RetTypeEnum<'lt>>::default()))
      },
      RawToken::Symbol(s) => Some(TerminalToken::from_raw(token,s,<RetTypeEnum<'lt>>::default())),
      RawToken::Alphanum(s) => Some(TerminalToken::from_raw(token,s,<RetTypeEnum<'lt>>::default())),
      _ => Some(TerminalToken::from_raw(token,"<LexicalError>",<RetTypeEnum<'lt>>::default())),
    }
  }
   fn linenum(&self) -> usize {self.stk.line()}
   fn column(&self) -> usize {self.stk.column()}
   fn position(&self) -> usize {self.stk.current_position()}
   fn current_line(&self) -> &str {self.stk.current_line()}
   fn get_line(&self,i:usize) -> Option<&str> {self.stk.get_line(i)}
   fn get_slice(&self,s:usize,l:usize) -> &str {self.stk.get_slice(s,l)}
   fn transform_wildcard(&self,t:TerminalToken<'lt,RetTypeEnum<'lt>>) -> TerminalToken<'lt,RetTypeEnum<'lt>> { TerminalToken::new(t.sym,RetTypeEnum::Enumvariant_2((self.stk.previous_position(),self.stk.current_position())),t.line,t.column) }
}//impl Tokenizer

fn load_extras<'lt>(parser:&mut ZCParser<RetTypeEnum<'lt>,()>)
{
}//end of load_extras: don't change this line as it affects augmentation
