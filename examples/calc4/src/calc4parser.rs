//Parser generated by rustlr for grammar calc4

#![allow(unused_variables)]
#![allow(non_snake_case)]
#![allow(non_camel_case_types)]
#![allow(unused_parens)]
#![allow(unused_mut)]
#![allow(unused_imports)]
#![allow(unused_assignments)]
#![allow(dead_code)]
#![allow(irrefutable_let_patterns)]
#![allow(unreachable_patterns)]
extern crate rustlr;
use rustlr::{Tokenizer,TerminalToken,ZCParser,ZCRProduction,Stateaction,decode_action};
use rustlr::{StrTokenizer,RawToken,LexSource};
use std::collections::{HashMap,HashSet};
use crate::exprtrees::*; /* ! lines are injected verbatim into parser */
use crate::exprtrees::Expr::*;
use rustlr::{LBox};

static SYMBOLS:[&'static str;17] = ["_WILDCARD_TOKEN_","E","ES","+","-","*","/","(",")","=",";","let","in","int","var","START","EOF"];

static TABLE:[u64;177] = [17180327936,8590065665,47244705792,4295229441,60129869824,30065164288,55834771456,281492157038592,281479272202241,281522221416448,281535106580480,281505041874944,281530811482112,563018672898051,562967133749248,563005788192768,562997198127104,562954248978433,562980018585600,563010083291136,844476469739522,844450699935746,844446404968450,844442110001154,844459289870338,844467879804930,844463584837634,844437815033858,1125925677498368,1125921382334464,1125942857236480,1125917087629312,1125912792530944,1407409243357186,1407392063488002,1407396358455298,1407387768520706,1407400653422594,1407426423226370,1407417833291778,1407413538324482,1688909990133760,1688854156214273,1688867040591872,1688905695035392,1688897104969728,1688879925428224,1970354902138880,1970329132990465,1970372081680384,1970384966844416,1970380671746048,1970342017302528,2251816994471936,2251821289177088,2251838469505024,2251812699373568,2251825584340992,2533300561051648,2533296265887744,2533291971182592,2533317741248512,2533287676084224,2814797011812352,2814809896976384,2814754063319041,2814779832270848,2814766947434496,2814805601878016,3096293463883778,3096280578981890,3096284873949186,3096254809178114,3096271989047298,3096241924276226,3377746965233664,3377759850397696,3377704016805889,3377729785692160,3377755555299328,3377716900855808,3659230532009984,3659221941944320,3659204762402816,3659234827108352,3659191877566464,3659178993582081,3940709803819008,3940696918654976,3940679739113472,3940653970358273,3940705508720640,3940666854277120,4222141831446528,4222146126151680,4222159011905536,4222150421315584,4222137536348160,4503616807632898,4503621102862336,4503638282469378,4503633987502082,4503612512665602,4503625398026240,4503642577436674,4503651167371266,4785134733950976,4785104669245440,4785130438852608,4785078900621313,4785091784409088,4785121848786944,5066579646218242,5066596826087426,5066605416022018,5066609710989314,5066566761316354,5066618300923906,5348041737699330,5348046032666626,5348058917568514,5348076097437698,5348063212535810,5348037442732034,5348050327633922,5348067507503106,5629551073951746,5629516714213378,5629533894082562,5629525304868864,5629542484017154,5629512419246082,5629521009704960,5629538189049858,5910987396087810,5911008870924290,5911013165891586,5911000280989698,5911026050793474,5910995986022402,5910991691055106,5911017460858882,6192475258290176,6192483847569410,6192492437504002,6192466667700226,6192470963126272,6192488142536706,6192501027438594,6192462372732930,6473967414476802,6473937349705730,6473941644673026,6473945939640322,6473963119509506,6473958824542210,6473950234607618,6473976004411394,6755416621842432,6755412326744064,6755425211711488,6755420916547584,6755450982301696,7036891598094336,7036904482930688,7036934547636224,7036930252537856,7036878714437633,7036921662472192,7318383754739714,7318388049707010,7318366575263744,7318392344674306,7318375165132800,7318370869968896,7318400934608898,7318362280165376,];

pub fn make_parser<'src_lt>() -> ZCParser<Expr<'src_lt>,i64>
{
 let mut parser1:ZCParser<Expr<'src_lt>,i64> = ZCParser::new(12,27);
 let mut rule = ZCRProduction::<Expr<'src_lt>,i64>::new_skeleton("start");
 rule = ZCRProduction::<Expr<'src_lt>,i64>::new_skeleton("E");
 rule.Ruleaction = |parser|{ let mut m = parser.popstack();  m.value };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Expr<'src_lt>,i64>::new_skeleton("E");
 rule.Ruleaction = |parser|{ let mut s = parser.popstack();  s.value };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Expr<'src_lt>,i64>::new_skeleton("E");
 rule.Ruleaction = |parser|{ let mut e2 = parser.popstack(); let mut _item1_ = parser.popstack(); let mut e1 = parser.popstack();  Plus(e1.lbox(),parser.lbx(2,e2.value)) };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Expr<'src_lt>,i64>::new_skeleton("E");
 rule.Ruleaction = |parser|{ let mut e2 = parser.popstack().lbox(); let mut _item1_ = parser.popstack(); let mut e1 = parser.popstack().lbox();  Minus(e1,e2)};
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Expr<'src_lt>,i64>::new_skeleton("E");
 rule.Ruleaction = |parser|{ let mut e2 = parser.popstack().lbox(); let mut _item1_ = parser.popstack(); let mut e1 = parser.popstack().lbox();  Divide(e1,e2) };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Expr<'src_lt>,i64>::new_skeleton("E");
 rule.Ruleaction = |parser|{ let mut e2 = parser.popstack().lbox(); let mut _item1_ = parser.popstack(); let mut e1 = parser.popstack().lbox();  Times(e1,e2) };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Expr<'src_lt>,i64>::new_skeleton("E");
 rule.Ruleaction = |parser|{ let mut e = parser.popstack().lbox(); let mut _item0_ = parser.popstack();  Negative(e) };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Expr<'src_lt>,i64>::new_skeleton("E");
 rule.Ruleaction = |parser|{ let mut _item2_ = parser.popstack(); let mut e = parser.popstack(); let mut _item0_ = parser.popstack();  e.value };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Expr<'src_lt>,i64>::new_skeleton("E");
 rule.Ruleaction = |parser|{ let mut b = parser.popstack().lbox(); let mut _item4_ = parser.popstack(); let mut e = parser.popstack().lbox(); let mut _item2_ = parser.popstack(); let mut _item1_ = parser.popstack(); let mut _item0_ = parser.popstack(); 
  if let (Var(x),)=(_item1_.value,) { Letexp(x,e,b)}  else {parser.bad_pattern("(Var(x),)")} };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Expr<'src_lt>,i64>::new_skeleton("ES");
 rule.Ruleaction = |parser|{ let mut _item1_ = parser.popstack(); let mut n = parser.popstack().lbox();  Seq(vec![n]) };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Expr<'src_lt>,i64>::new_skeleton("ES");
 rule.Ruleaction = |parser|{ let mut _item2_ = parser.popstack(); let mut e = parser.popstack().lbox(); let mut _item0_ = parser.popstack(); 
  if let (Seq(mut v),)=(_item0_.value,) { 
   v.push(e);
   Seq(v)
   }  else {parser.bad_pattern("(Seq(mut v),)")} };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Expr<'src_lt>,i64>::new_skeleton("START");
 rule.Ruleaction = |parser|{ let mut _item0_ = parser.popstack(); <Expr<'src_lt>>::default()};
 parser1.Rules.push(rule);
 parser1.Errsym = "";
 parser1.resynch.insert(";");

 for i in 0..177 {
   let symi = ((TABLE[i] & 0x0000ffff00000000) >> 32) as usize;
   let sti = ((TABLE[i] & 0xffff000000000000) >> 48) as usize;
   parser1.RSM[sti].insert(SYMBOLS[symi],decode_action(TABLE[i]));
 }

 for s in SYMBOLS { parser1.Symset.insert(s); }

 load_extras(&mut parser1);
 return parser1;
} //make_parser

pub fn parse_with<'src_lt>(parser:&mut ZCParser<Expr<'src_lt>,i64>, lexer:&mut calc4lexer<'src_lt>) -> Result<Expr<'src_lt>,Expr<'src_lt>>
{
  let _xres_ = parser.parse(lexer);  if !parser.error_occurred() {Ok(_xres_)} else {Err(_xres_)}
}//parse_with public function

pub fn parse_train_with<'src_lt>(parser:&mut ZCParser<Expr<'src_lt>,i64>, lexer:&mut calc4lexer<'src_lt>, parserpath:&str) -> Result<Expr<'src_lt>,Expr<'src_lt>>
{
  let _xres_ = parser.parse_train(lexer,parserpath);  if !parser.error_occurred() {Ok(_xres_)} else {Err(_xres_)}
}//parse_train_with public function

// Lexical Scanner using RawToken and StrTokenizer
pub struct calc4lexer<'t> {
   stk: StrTokenizer<'t>,
   keywords: HashSet<&'static str>,
   lexnames: HashMap<&'static str,&'static str>,
}
impl<'t> calc4lexer<'t> 
{
  pub fn from_str(s:&'t str) -> calc4lexer<'t>  {
    Self::new(StrTokenizer::from_str(s))
  }
  pub fn from_source(s:&'t LexSource<'t>) -> calc4lexer<'t>  {
    Self::new(StrTokenizer::from_source(s))
  }
  pub fn new(mut stk:StrTokenizer<'t>) -> calc4lexer<'t> {
    let mut lexnames = HashMap::with_capacity(64);
    let mut keywords = HashSet::with_capacity(64);
    for kw in ["_WILDCARD_TOKEN_","in","let",] {keywords.insert(kw);}
    for c in ['+','-','*','/','(',')','=',';',] {stk.add_single(c);}
    for d in [] {stk.add_double(d);}
    for d in [] {stk.add_triple(d);}
    for (k,v) in [] {lexnames.insert(k,v);}
    stk.set_line_comment("#");
    calc4lexer {stk,keywords,lexnames}
  }
}
impl<'src_lt> Tokenizer<'src_lt,Expr<'src_lt>> for calc4lexer<'src_lt>
{
   fn nextsym(&mut self) -> Option<TerminalToken<'src_lt,Expr<'src_lt>>> {
    let tokopt = self.stk.next_token();
    if let None = tokopt {return None;}
    let token = tokopt.unwrap();
    match token.0 {
      RawToken::Alphanum(sym) if self.keywords.contains(sym) => {
        let truesym = self.lexnames.get(sym).unwrap_or(&sym);
        Some(TerminalToken::from_raw(token,truesym,<Expr<'src_lt>>::default()))
      },
      RawToken::Num(n) => Some(TerminalToken::from_raw(token,"int",Val(n))),
      RawToken::Alphanum(x) => Some(TerminalToken::from_raw(token,"var",Var(x))),
      RawToken::Symbol(s) if self.lexnames.contains_key(s) => {
        let tname = self.lexnames.get(s).unwrap();
        Some(TerminalToken::from_raw(token,tname,<Expr<'src_lt>>::default()))
      },
      RawToken::Symbol(s) => Some(TerminalToken::from_raw(token,s,<Expr<'src_lt>>::default())),
      RawToken::Alphanum(s) => Some(TerminalToken::from_raw(token,s,<Expr<'src_lt>>::default())),
      _ => Some(TerminalToken::from_raw(token,"<LexicalError>",<Expr<'src_lt>>::default())),
    }
  }
   fn linenum(&self) -> usize {self.stk.line()}
   fn column(&self) -> usize {self.stk.column()}
   fn position(&self) -> usize {self.stk.current_position()}
   fn current_line(&self) -> &str {self.stk.current_line()}
   fn get_line(&self,i:usize) -> Option<&str> {self.stk.get_line(i)}
}//impl Tokenizer

fn load_extras<'src_lt>(parser:&mut ZCParser<Expr<'src_lt>,i64>)
{
  parser.RSM[3].insert("ANY_ERROR",Stateaction::Error("unsupported operator"));
  parser.RSM[3].insert("var",Stateaction::Error("variables are not allowed at this position"));
}//end of load_extras: don't change this line as it affects augmentation
