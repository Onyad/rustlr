//Parser generated by rustlr for grammar wc
    
#![allow(unused_variables)]
#![allow(non_snake_case)]
#![allow(non_camel_case_types)]
#![allow(unused_parens)]
#![allow(unused_mut)]
#![allow(unused_imports)]
#![allow(unused_assignments)]
#![allow(dead_code)]
#![allow(unreachable_patterns)]
#![allow(irrefutable_let_patterns)]
extern crate rustlr;
use rustlr::{Tokenizer,TerminalToken,ZCParser,ZCRProduction,Stateaction,decode_action};
use rustlr::{StrTokenizer,RawToken,LexSource};
use std::collections::{HashMap,HashSet};
use rustlr::LBox;
use crate::wc_ast;
use crate::wc_ast::*;

static SYMBOLS:[&'static str;11] = ["_WILDCARD_TOKEN_","VAL","a","b","i32","c","E","T","NT2","START","EOF"];

static TABLE:[u64;21] = [8590000128,25769934849,281487861809152,281474977103872,281505041809409,281509336711169,562992903094275,844437815033858,844424930131970,1125929972137985,1125899907235840,1125912792203264,1407374883684354,1407387768586242,1688862745231362,1688849860329474,1970337721876482,1970367786909698,1970324836974594,2251799813881858,2251812698783746,];


fn _semaction_rule_0_(parser:&mut ZCParser<RetTypeEnum,()>) -> () {
let mut _item0_ = if let RetTypeEnum::Enumvariant_5(_x_5)=parser.popstack().value { _x_5 } else {<()>::default()}; <()>::default()}

fn _semaction_rule_1_(parser:&mut ZCParser<RetTypeEnum,()>) -> () {
let mut _item0_ = if let RetTypeEnum::Enumvariant_5(_x_5)=parser.popstack().value { _x_5 } else {<()>::default()}; <()>::default()}

fn _semaction_rule_2_(parser:&mut ZCParser<RetTypeEnum,()>) -> () {
let mut _item0_ = if let RetTypeEnum::Enumvariant_5(_x_5)=parser.popstack().value { _x_5 } else {<()>::default()}; <()>::default()}

fn _semaction_rule_3_(parser:&mut ZCParser<RetTypeEnum,()>) -> () {
let mut _item1_ = if let RetTypeEnum::Enumvariant_5(_x_5)=parser.popstack().value { _x_5 } else {<()>::default()}; let mut _item0_ = if let RetTypeEnum::Enumvariant_5(_x_5)=parser.popstack().value { _x_5 } else {<()>::default()}; <()>::default()}

fn _semaction_rule_4_(parser:&mut ZCParser<RetTypeEnum,()>) -> E {
let mut _item2_ = if let RetTypeEnum::Enumvariant_5(_x_5)=parser.popstack().value { _x_5 } else {<()>::default()}; let mut _item1_ = if let RetTypeEnum::Enumvariant_5(_x_5)=parser.popstack().value { _x_5 } else {<()>::default()}; let mut _item0_ = if let RetTypeEnum::Enumvariant_3(_x_3)=parser.popstack().value { _x_3 } else {<i32>::default()}; E::a_4(_item0_) }

fn _semaction_rule_5_(parser:&mut ZCParser<RetTypeEnum,()>) -> E {
let mut _item0_ = if let RetTypeEnum::Enumvariant_0(_x_0)=parser.popstack().value { _x_0 } else {<E>::default()}; <E>::default()}

pub fn make_parser() -> ZCParser<RetTypeEnum,()>
{
 let mut parser1:ZCParser<RetTypeEnum,()> = ZCParser::new(6,9);
 let mut rule = ZCRProduction::<RetTypeEnum,()>::new_skeleton("start");
 rule = ZCRProduction::<RetTypeEnum,()>::new_skeleton("T");
 rule.Ruleaction = |parser|{  RetTypeEnum::Enumvariant_5(_semaction_rule_0_(parser)) };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<RetTypeEnum,()>::new_skeleton("T");
 rule.Ruleaction = |parser|{  RetTypeEnum::Enumvariant_5(_semaction_rule_1_(parser)) };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<RetTypeEnum,()>::new_skeleton("NT2");
 rule.Ruleaction = |parser|{  RetTypeEnum::Enumvariant_5(_semaction_rule_2_(parser)) };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<RetTypeEnum,()>::new_skeleton("NT2");
 rule.Ruleaction = |parser|{  RetTypeEnum::Enumvariant_5(_semaction_rule_3_(parser)) };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<RetTypeEnum,()>::new_skeleton("E");
 rule.Ruleaction = |parser|{  RetTypeEnum::Enumvariant_0(_semaction_rule_4_(parser)) };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<RetTypeEnum,()>::new_skeleton("START");
 rule.Ruleaction = |parser|{  RetTypeEnum::Enumvariant_0(_semaction_rule_5_(parser)) };
 parser1.Rules.push(rule);
 parser1.Errsym = "";

 for i in 0..21 {
   let symi = ((TABLE[i] & 0x0000ffff00000000) >> 32) as usize;
   let sti = ((TABLE[i] & 0xffff000000000000) >> 48) as usize;
   parser1.RSM[sti].insert(SYMBOLS[symi],decode_action(TABLE[i]));
 }

 for s in SYMBOLS { parser1.Symset.insert(s); }

 load_extras(&mut parser1);
 return parser1;
} //make_parser

pub fn parse_with<'t>(parser:&mut ZCParser<RetTypeEnum,()>, lexer:&mut wclexer<'t>) -> Result<E,E>
{
  if let RetTypeEnum::Enumvariant_0(_xres_) = parser.parse(lexer) {
     if !parser.error_occurred() {Ok(_xres_)} else {Err(_xres_)}
  } else { Err(<E>::default())}
}//parse_with public function

pub fn parse_train_with<'t>(parser:&mut ZCParser<RetTypeEnum,()>, lexer:&mut wclexer<'t>, parserpath:&str) -> Result<E,E>
{
  if let RetTypeEnum::Enumvariant_0(_xres_) = parser.parse_train(lexer,parserpath) {
     if !parser.error_occurred() {Ok(_xres_)} else {Err(_xres_)}
  } else { Err(<E>::default())}
}//parse_train_with public function

//Enum for return values 
pub enum RetTypeEnum {
  Enumvariant_0(E),
  Enumvariant_5(()),
  Enumvariant_2(i64),
  Enumvariant_3(i32),
}
impl Default for RetTypeEnum { fn default()->Self {RetTypeEnum::Enumvariant_0(<E>::default())} }


// Lexical Scanner using RawToken and StrTokenizer
pub struct wclexer<'t> {
   stk: StrTokenizer<'t>,
   keywords: HashSet<&'static str>,
   lexnames: HashMap<&'static str,&'static str>,
}
impl<'t> wclexer<'t> 
{
  pub fn from_str(s:&'t str) -> wclexer<'t>  {
    Self::new(StrTokenizer::from_str(s))
  }
  pub fn from_source(s:&'t LexSource<'t>) -> wclexer<'t>  {
    Self::new(StrTokenizer::from_source(s))
  }
  pub fn new(mut stk:StrTokenizer<'t>) -> wclexer<'t> {
    let mut lexnames = HashMap::with_capacity(64);
    let mut keywords = HashSet::with_capacity(64);
    for kw in ["c","a","_WILDCARD_TOKEN_","i32","b",] {keywords.insert(kw);}
    for c in [] {stk.add_single(c);}
    for d in [] {stk.add_double(d);}
    for d in [] {stk.add_triple(d);}
    for (k,v) in [] {lexnames.insert(k,v);}
    wclexer {stk,keywords,lexnames}
  }
}
impl<'t> Tokenizer<'t,RetTypeEnum> for wclexer<'t>
{
   fn nextsym(&mut self) -> Option<TerminalToken<'t,RetTypeEnum>> {
    let tokopt = self.stk.next_token();
    if let None = tokopt {return None;}
    let token = tokopt.unwrap();
    match token.0 {
      RawToken::Alphanum(sym) if self.keywords.contains(sym) => {
        let truesym = self.lexnames.get(sym).unwrap_or(&sym);
        Some(TerminalToken::from_raw(token,truesym,<RetTypeEnum>::default()))
      },
      RawToken::Num(n) => Some(TerminalToken::from_raw(token,"VAL",RetTypeEnum::Enumvariant_2(n))),
      RawToken::Symbol(s) if self.lexnames.contains_key(s) => {
        let tname = self.lexnames.get(s).unwrap();
        Some(TerminalToken::from_raw(token,tname,<RetTypeEnum>::default()))
      },
      RawToken::Symbol(s) => Some(TerminalToken::from_raw(token,s,<RetTypeEnum>::default())),
      RawToken::Alphanum(s) => Some(TerminalToken::from_raw(token,s,<RetTypeEnum>::default())),
      _ => Some(TerminalToken::from_raw(token,"<LexicalError>",<RetTypeEnum>::default())),
    }
  }
   fn linenum(&self) -> usize {self.stk.line()}
   fn column(&self) -> usize {self.stk.column()}
   fn position(&self) -> usize {self.stk.current_position()}
   fn current_line(&self) -> &str {self.stk.current_line()}
   fn get_line(&self,i:usize) -> Option<&str> {self.stk.get_line(i)}
}//impl Tokenizer

fn load_extras(parser:&mut ZCParser<RetTypeEnum,()>)
{
}//end of load_extras: don't change this line as it affects augmentation
